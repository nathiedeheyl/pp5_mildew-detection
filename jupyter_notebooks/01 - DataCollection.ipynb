{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection and Preparation Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and prepare it.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file as authentication token\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset: inputs/mildew_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Set working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/nathalievonheyl/Documents/ci-code_institute/PP5/pp5_mildew-detection/jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/nathalievonheyl/Documents/ci-code_institute/PP5/pp5_mildew-detection'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Install and download Kaggle data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change kaggle configuration directory to current working directory and permission of kaggle authentication json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download Kaggle dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/codeinstitute/cherry-leaves\n",
            "License(s): unknown\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/mildew_dataset\"\n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "zip_path = os.path.join(DestinationFolder, \"cherry-leaves.zip\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "  zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Data Cleaning and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning: Remove non-image files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the dynamic file path construction, I am using `os.path.join()` to avoid errors while concatenating strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "  \"\"\"\n",
        "  Function to remove non-image files from the dataset directory.\n",
        "\n",
        "  Args:\n",
        "  * my_data_dir = path to image dataset folder\n",
        "  \"\"\"\n",
        "  image_extension = ('.png', '.jpg', '.jpeg')\n",
        "  folders = os.listdir(my_data_dir)  \n",
        "  for folder in folders:\n",
        "    folder_path =  os.path.join(my_data_dir, folder)\n",
        "\n",
        "    if not os.path.isdir(folder_path):\n",
        "      continue\n",
        "\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    i = []\n",
        "    j = []\n",
        "    for given_file in files:\n",
        "      if not given_file.lower().endswith(image_extension):\n",
        "        file_location = os.path.join(my_data_dir, folder, given_file)\n",
        "        os.remove(file_location)\n",
        "        i.append(1)\n",
        "      else:\n",
        "        j.append(1)\n",
        "        pass\n",
        "    print(f\"Folder: {folder} - has image file\", len(j))\n",
        "    print(f\"Folder: {folder} - has non-image file\", len(i))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From previous experience, I discovered that the macOS Finder creates `.DS_Store` files in every folder. These files are not actually folders, but `os.listdir()` can mistakenly include them in the list of folders. This then can cause errors when trying to further process the directories as class labels in image classification. \n",
        "\n",
        "I included an if/else statement to check whether an item is a real directory using `os.path.isdir()`. `.DS_Store` files are then already skipped in this process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder: powdery_mildew - has image file 2104\n",
            "Folder: powdery_mildew - has non-image file 0\n",
            "Folder: healthy - has image file 2104\n",
            "Folder: healthy - has non-image file 0\n"
          ]
        }
      ],
      "source": [
        "remove_non_image_file(my_data_dir='inputs/mildew_dataset/cherry-leaves')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split data into train and validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Organize the image dataset into train, validation, and test sets. This is essential for the ml model to be properly trained.\n",
        "\n",
        "Here's what the function does:\n",
        "\n",
        "- Validate that the provided split ratios sum to 1\n",
        "- Check if dataset is already split based on search for existance of 'test' directory and if check positive exit function to avoid unnecessary processing\n",
        "- Create the 'train', 'validation', and 'test' directories if check negative and they do not yet exist\n",
        "- Randomize the image dataset and distribute files to new direcotires according to the ratio distribution\n",
        "- Place images into their respective dataset folders\n",
        "- Remove original class folders after successfully moving all images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_dataset_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "  \"\"\"\n",
        "  Function to split images into train, validation, and test sets.\n",
        "\n",
        "  The function assumes `my_data_dir` contains folders representing class labels.\n",
        "  \n",
        "  Args:\n",
        "  * my_data_dir = path to image dataset folder\n",
        "  * train_set_ratio = float between 0-1\n",
        "  * validation_set_ratio = float between 0-1\n",
        "  * test_set_ratio = float between 0-1\n",
        "  \"\"\"\n",
        "  # make sure ratio of datasets sum is 1\n",
        "  if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "  \n",
        "  # get list of labels (folders)\n",
        "  labels = os.listdir(my_data_dir)\n",
        "\n",
        "  # detect if datasets have already been split\n",
        "  if os.path.exists(os.path.join(my_data_dir, 'test')):\n",
        "      print(\"Datasets have already been split.\")\n",
        "      return\n",
        "  \n",
        "  #create train, validation, and test folder with subfolders \"healthy\" and \"powdery_mildew\"\n",
        "  else:\n",
        "      for folder in ['train', 'validation', 'test']:\n",
        "          for label in labels:\n",
        "              os.makedirs(os.path.join(my_data_dir, folder, label))\n",
        "\n",
        "      # looping through labels\n",
        "      for label in labels:\n",
        "          \n",
        "          files = os.listdir(os.path.join(my_data_dir, label))\n",
        "          random.shuffle(files)\n",
        "\n",
        "          # calculate number of files per directory according to ratio\n",
        "          train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "          validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "          # move img data into new folders\n",
        "          count = 1\n",
        "          for file_name in files:\n",
        "              if count <= train_set_files_qty:\n",
        "                  shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                              os.path.join(my_data_dir, 'train', label, file_name))\n",
        "\n",
        "              elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                  shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                              os.path.join(my_data_dir, 'validation', label, file_name))\n",
        "                  \n",
        "              else:\n",
        "                  shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                              os.path.join(my_data_dir, 'test', label, file_name))\n",
        "              \n",
        "              count += 1\n",
        "          \n",
        "          # delete original category folders after moving files\n",
        "          os.rmdir(os.path.join(my_data_dir, label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_dataset_images(my_data_dir=f\"inputs/mildew_dataset/cherry-leaves\",\n",
        "                     train_set_ratio=0.7,\n",
        "                     validation_set_ratio=0.1,\n",
        "                     test_set_ratio=0.2\n",
        "                     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Conclusion and next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conclusion**\n",
        "\n",
        "The original image dataset containing images classified by \"healthy\" and \"powdery_mildew\" has been successfully reorganized into structured 'train', 'validation', and 'test' directories with the respective subfolders containing the original class labels. \n",
        "\n",
        "The `remove_non_image_file` function handels the following points:\n",
        "- Removing non-image files\n",
        "- Skipping hidden files that could be mistakenly interpreted as class labels (e.g. .DS_Store)\n",
        "\n",
        "The original unstructured dataset is removed. The split datasets are ready for DataVisualization.\n",
        "\n",
        "**Next Steps**\n",
        "\n",
        "The now structured image data is visualized to understand and verify dataset features. \n",
        "Key objectives:\n",
        "- Determining class distribution between \"healthy\" and \"powdery_mildew\" images throughout the split datasets\n",
        "- Determining and plotting mean and variablity images for the two class labels\n",
        "- Creating an image montage for the dashboard of the future app"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "mildew_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
